{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiogoLepri/ASD2_Project/blob/main/ASD_DiagNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mVAfnd06ES9",
        "outputId": "2d6bb011-f3f8-4982-f89b-10eb45e93d36"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ASD2_Project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnJkylVA6DuC",
        "outputId": "83442a08-c4bf-4943-d29e-ca82a0e54734"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASD2_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib scikit-learn torch pyprind scipy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0I3QvBKj_lM",
        "outputId": "0e3afb7d-9e42-45e3-bd9b-892441658e74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyprind-2.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "IF69HS76je7I"
      },
      "outputs": [],
      "source": [
        "#options: cc200, dosenbach160, aal\n",
        "p_ROI = \"cc200\"\n",
        "p_fold = 10\n",
        "p_center = \"Stanford\"\n",
        "p_mode = \"whole\"\n",
        "p_augmentation = True\n",
        "p_Method = \"ASD-DiagNet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Oc4GXGje7K",
        "outputId": "28954098-fad7-4918-8e2c-fedd0f46a686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****List of patameters****\n",
            "ROI atlas:  cc200\n",
            "per Center or whole:  whole\n",
            "Method's name:  ASD-DiagNet\n",
            "Augmentation:  True\n"
          ]
        }
      ],
      "source": [
        "parameter_list = [p_ROI,p_fold,p_center,p_mode,p_augmentation,p_Method]\n",
        "print(\"*****List of patameters****\")\n",
        "print(\"ROI atlas: \",p_ROI)\n",
        "print(\"per Center or whole: \",p_mode)\n",
        "if p_mode == 'percenter':\n",
        "    print(\"Center's name: \",p_center)\n",
        "print(\"Method's name: \",p_Method)\n",
        "if p_Method == \"ASD-DiagNet\":\n",
        "    print(\"Augmentation: \",p_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jUGCxT3qje7L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from functools import reduce\n",
        "from sklearn.impute import SimpleImputer\n",
        "import time\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import pyprind\n",
        "import sys\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy import stats\n",
        "from sklearn import tree\n",
        "import functools\n",
        "import numpy.ma as ma # for masked arrays\n",
        "import pyprind\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7-Rr-nGje7L"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bp8xZtF5je7M"
      },
      "outputs": [],
      "source": [
        "def get_key(filename):\n",
        "    f_split = filename.split('_')\n",
        "    if f_split[3] == 'rois':\n",
        "        key = '_'.join(f_split[0:3])\n",
        "    else:\n",
        "        key = '_'.join(f_split[0:2])\n",
        "    return key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_zvQk6fje7M",
        "outputId": "e971f34a-c97c-4448-a7e0-2afc671b6580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "884\n",
            "1112\n"
          ]
        }
      ],
      "source": [
        "data_main_path = f'/content/drive/MyDrive/ASD2_Project/Outputs/cpac/filt_global/rois_{p_ROI}'#path to time series data\n",
        "flist = os.listdir(data_main_path)\n",
        "print(len(flist))\n",
        "\n",
        "for f in range(len(flist)):\n",
        "    flist[f] = get_key(flist[f])\n",
        "\n",
        "\n",
        "df_labels = pd.read_csv('/content/drive/MyDrive/ASD2_Project/Phenotypic_V1_0b_preprocessed1.csv')#path\n",
        "\n",
        "df_labels.DX_GROUP = df_labels.DX_GROUP.map({1: 1, 2:0})\n",
        "print(len(df_labels))\n",
        "\n",
        "labels = {}\n",
        "for row in df_labels.iterrows():\n",
        "    file_id = row[1]['FILE_ID']\n",
        "    y_label = row[1]['DX_GROUP']\n",
        "    if file_id == 'no_filename':\n",
        "        continue\n",
        "    assert(file_id not in labels)\n",
        "    labels[file_id] = y_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP1zt_HDje7M"
      },
      "source": [
        "### Helper functions for computing correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a7y4oZhgje7M"
      },
      "outputs": [],
      "source": [
        "def get_label(filename):\n",
        "    assert (filename in labels)\n",
        "    return labels[filename]\n",
        "\n",
        "\n",
        "def get_corr_data(filename):\n",
        "    #print(filename)\n",
        "    for file in os.listdir(data_main_path):\n",
        "        if file.startswith(filename):\n",
        "            df = pd.read_csv(os.path.join(data_main_path, file), sep='\\t')\n",
        "\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        corr = np.nan_to_num(np.corrcoef(df.T))\n",
        "        mask = np.invert(np.tri(corr.shape[0], k=-1, dtype=bool))\n",
        "        m = ma.masked_where(mask == 1, mask)\n",
        "        return ma.masked_where(m, corr).compressed()\n",
        "\n",
        "def get_corr_matrix(filename):\n",
        "    for file in os.listdir(data_main_path):\n",
        "        if file.startswith(filename):\n",
        "            df = pd.read_csv(os.path.join(data_main_path, file), sep='\\t')\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        corr = np.nan_to_num(np.corrcoef(df.T))\n",
        "        return corr\n",
        "\n",
        "def confusion(g_turth,predictions):\n",
        "    tn, fp, fn, tp = confusion_matrix(g_turth,predictions).ravel()\n",
        "    accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
        "    sensitivity = (tp)/(tp+fn)\n",
        "    specificty = (tn)/(tn+fp)\n",
        "    return accuracy,sensitivity,specificty\n",
        "\n",
        "def get_regs(samplesnames,regnum):\n",
        "    datas = []\n",
        "    for sn in samplesnames:\n",
        "        datas.append(all_corr[sn][0])\n",
        "    datas = np.array(datas)\n",
        "    avg=[]\n",
        "    for ie in range(datas.shape[1]):\n",
        "        avg.append(np.mean(datas[:,ie]))\n",
        "    avg=np.array(avg)\n",
        "    highs=avg.argsort()[-regnum:][::-1]\n",
        "    lows=avg.argsort()[:regnum][::-1]\n",
        "    regions=np.concatenate((highs,lows),axis=0)\n",
        "    return regions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_df_Lrp8je7M"
      },
      "source": [
        "## Helper fnuctions for computing correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_980i7pjje7N"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('./correlations_file'+p_ROI+'.pkl'):\n",
        "    pbar=pyprind.ProgBar(len(flist))\n",
        "    all_corr = {}\n",
        "    for f in flist:\n",
        "\n",
        "        lab = get_label(f)\n",
        "        all_corr[f] = (get_corr_data(f), lab)\n",
        "        pbar.update()\n",
        "\n",
        "    print('Corr-computations finished')\n",
        "\n",
        "    pickle.dump(all_corr, open('./correlations_file'+p_ROI+'.pkl', 'wb'))\n",
        "    print('Saving to file finished')\n",
        "\n",
        "else:\n",
        "    all_corr = pickle.load(open('./correlations_file'+p_ROI+'.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vFuNrLsje7N"
      },
      "source": [
        "## Computing eigenvalues and eigenvector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Putbeqefje7N",
        "outputId": "e727a8e0-5738-4e1a-9f07-b61aae9e1d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:56\n"
          ]
        }
      ],
      "source": [
        "if p_Method==\"ASD-DiagNet\":\n",
        "    eig_data = {}\n",
        "    pbar = pyprind.ProgBar(len(flist))\n",
        "    for f in flist:\n",
        "        d = get_corr_matrix(f)\n",
        "        eig_vals, eig_vecs = np.linalg.eig(d)\n",
        "\n",
        "        for ev in eig_vecs.T:\n",
        "            np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
        "\n",
        "        sum_eigvals = np.sum(np.abs(eig_vals))\n",
        "        # Make a list of (eigenvalue, eigenvector, norm_eigval) tuples\n",
        "        eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i], np.abs(eig_vals[i])/sum_eigvals)\n",
        "                     for i in range(len(eig_vals))]\n",
        "\n",
        "        # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
        "        eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        eig_data[f] = {'eigvals':np.array([ep[0] for ep in eig_pairs]),\n",
        "                       'norm-eigvals':np.array([ep[2] for ep in eig_pairs]),\n",
        "                       'eigvecs':[ep[1] for ep in eig_pairs]}\n",
        "        pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mUbBcVXje7N"
      },
      "source": [
        "## Calculating Eros similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y9GN9yITje7N"
      },
      "outputs": [],
      "source": [
        "def norm_weights(sub_flist):\n",
        "    num_dim = len(eig_data[flist[0]]['eigvals'])\n",
        "    norm_weights = np.zeros(shape=num_dim)\n",
        "    for f in sub_flist:\n",
        "        norm_weights += eig_data[f]['norm-eigvals']\n",
        "    return norm_weights\n",
        "\n",
        "def cal_similarity(d1, d2, weights, lim=None):\n",
        "    res = 0.0\n",
        "    if lim is None:\n",
        "        weights_arr = weights.copy()\n",
        "    else:\n",
        "        weights_arr = weights[:lim].copy()\n",
        "        weights_arr /= np.sum(weights_arr)\n",
        "    for i,w in enumerate(weights_arr):\n",
        "        res += w*np.inner(d1[i], d2[i])\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmfYEmZije7N"
      },
      "source": [
        "## Defining dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aiJEROcRje7N"
      },
      "outputs": [],
      "source": [
        "class CC200Dataset(Dataset):\n",
        "    def __init__(self, pkl_filename=None, data=None, samples_list=None,\n",
        "                 augmentation=False, aug_factor=1, num_neighbs=5,\n",
        "                 eig_data=None, similarity_fn=None, verbose=False,regs=None):\n",
        "        self.regs=regs\n",
        "        if pkl_filename is not None:\n",
        "            if verbose:\n",
        "                print ('Loading ..!', end=' ')\n",
        "            self.data = pickle.load(open(pkl_filename, 'rb'))\n",
        "        elif data is not None:\n",
        "            self.data = data.copy()\n",
        "\n",
        "        else:\n",
        "            sys.stderr.write('Eigther PKL file or data is needed!')\n",
        "            return\n",
        "\n",
        "        #if verbose:\n",
        "        #    print ('Preprocess..!', end='  ')\n",
        "        if samples_list is None:\n",
        "            self.flist = [f for f in self.data]\n",
        "        else:\n",
        "            self.flist = [f for f in samples_list]\n",
        "        self.labels = np.array([self.data[f][1] for f in self.flist])\n",
        "\n",
        "        current_flist = np.array(self.flist.copy())\n",
        "        current_lab0_flist = current_flist[self.labels == 0]\n",
        "        current_lab1_flist = current_flist[self.labels == 1]\n",
        "        #if verbose:\n",
        "        #    print(' Num Positive : ', len(current_lab1_flist), end=' ')\n",
        "        #    print(' Num Negative : ', len(current_lab0_flist), end=' ')\n",
        "\n",
        "\n",
        "        if augmentation:\n",
        "            self.num_data = aug_factor * len(self.flist)\n",
        "            self.neighbors = {}\n",
        "            pbar = pyprind.ProgBar(len(self.flist))\n",
        "            weights = norm_weights(samples_list)#??\n",
        "            for f in self.flist:\n",
        "                label = self.data[f][1]\n",
        "                candidates = (set(current_lab0_flist) if label == 0 else set(current_lab1_flist))\n",
        "                candidates.remove(f)\n",
        "                eig_f = eig_data[f]['eigvecs']\n",
        "                sim_list = []\n",
        "                for cand in candidates:\n",
        "                    eig_cand = eig_data[cand]['eigvecs']\n",
        "                    sim = similarity_fn(eig_f, eig_cand,weights)\n",
        "                    sim_list.append((sim, cand))\n",
        "                sim_list.sort(key=lambda x: x[0], reverse=True)\n",
        "                self.neighbors[f] = [item[1] for item in sim_list[:num_neighbs]]#list(candidates)#[item[1] for item in sim_list[:num_neighbs]]\n",
        "\n",
        "        else:\n",
        "            self.num_data = len(self.flist)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index < len(self.flist):\n",
        "            fname = self.flist[index]\n",
        "            data = self.data[fname][0].copy() #get_corr_data(fname, mode=cal_mode)\n",
        "            data = data[self.regs].copy()\n",
        "            label = (self.labels[index],)\n",
        "            return torch.FloatTensor(data), torch.FloatTensor(label)\n",
        "        else:\n",
        "            f1 = self.flist[index % len(self.flist)]\n",
        "            d1, y1 = self.data[f1][0], self.data[f1][1]\n",
        "            d1=d1[self.regs]\n",
        "            f2 = np.random.choice(self.neighbors[f1])\n",
        "            d2, y2 = self.data[f2][0], self.data[f2][1]\n",
        "            d2=d2[self.regs]\n",
        "            assert y1 == y2\n",
        "            r = np.random.uniform(low=0, high=1)\n",
        "            label = (y1,)\n",
        "            data = r*d1 + (1-r)*d2\n",
        "            return torch.FloatTensor(data), torch.FloatTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfUMb1Z2je7O"
      },
      "source": [
        "## Definig data loader function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GlGMx4Lrje7O"
      },
      "outputs": [],
      "source": [
        "def get_loader(pkl_filename=None, data=None, samples_list=None,\n",
        "               batch_size=64,\n",
        "               num_workers=1, mode='train',\n",
        "               *, augmentation=False, aug_factor=1, num_neighbs=5,\n",
        "                 eig_data=None, similarity_fn=None, verbose=False,regions=None):\n",
        "    \"\"\"Build and return data loader.\"\"\"\n",
        "    if mode == 'train':\n",
        "        shuffle = True\n",
        "    else:\n",
        "        shuffle = False\n",
        "        augmentation=False\n",
        "\n",
        "    dataset = CC200Dataset(pkl_filename=pkl_filename, data=data, samples_list=samples_list,\n",
        "                           augmentation=augmentation, aug_factor=aug_factor,\n",
        "                           eig_data=eig_data, similarity_fn=similarity_fn, verbose=verbose,regs=regions)\n",
        "\n",
        "    data_loader = DataLoader(dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=shuffle,\n",
        "                             num_workers=num_workers)\n",
        "\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK8W0nMSje7O"
      },
      "source": [
        "## Defining Autoencoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1pd8JMdje7O",
        "outputId": "08ad75b6-0f1b-49b1-97f5-d4baa15b0a57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAutoEncoder(\n",
              "  (fc_encoder): Linear(in_features=990, out_features=200, bias=True)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=200, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "class MTAutoEncoder(nn.Module):\n",
        "    def __init__(self, num_inputs=990,\n",
        "                 num_latent=200, tied=True,\n",
        "                 num_classes=2, use_dropout=False):\n",
        "        super(MTAutoEncoder, self).__init__()\n",
        "        self.tied = tied\n",
        "        self.num_latent = num_latent\n",
        "\n",
        "        self.fc_encoder = nn.Linear(num_inputs, num_latent)\n",
        "\n",
        "        if not tied:\n",
        "            self.fc_decoder = nn.Linear(num_latent, num_inputs)\n",
        "\n",
        "        self.fc_encoder = nn.Linear(num_inputs, num_latent)\n",
        "\n",
        "        if use_dropout:\n",
        "            self.classifier = nn.Sequential (\n",
        "                nn.Dropout(p=0.5),\n",
        "                nn.Linear(self.num_latent, 1),\n",
        "\n",
        "            )\n",
        "        else:\n",
        "            self.classifier = nn.Sequential (\n",
        "                nn.Linear(self.num_latent, 1),\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, x, eval_classifier=False):\n",
        "        x = self.fc_encoder(x)\n",
        "        x = torch.tanh(x)\n",
        "        if eval_classifier:\n",
        "            x_logit = self.classifier(x)\n",
        "        else:\n",
        "            x_logit = None\n",
        "\n",
        "        if self.tied:\n",
        "            x = F.linear(x, self.fc_encoder.weight.t())\n",
        "        else:\n",
        "            x = self.fc_decoder(x)\n",
        "\n",
        "        return x, x_logit\n",
        "\n",
        "mtae = MTAutoEncoder()\n",
        "\n",
        "mtae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLxPmE4kje7O"
      },
      "source": [
        "## Defining training and testing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Glfo2XVQje7O"
      },
      "outputs": [],
      "source": [
        "def train(model, epoch, train_loader, p_bernoulli=None, mode='both', lam_factor=1.0):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for i,(batch_x,batch_y) in enumerate(train_loader):\n",
        "        if len(batch_x) != batch_size:\n",
        "            continue\n",
        "        if p_bernoulli is not None:\n",
        "            if i == 0:\n",
        "                p_tensor = torch.ones_like(batch_x).to(device)*p_bernoulli\n",
        "            rand_bernoulli = torch.bernoulli(p_tensor).to(device)\n",
        "\n",
        "        data, target = batch_x.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if mode in ['both', 'ae']:\n",
        "            if p_bernoulli is not None:\n",
        "                rec_noisy, _ = model(data*rand_bernoulli, False)\n",
        "                loss_ae = criterion_ae(rec_noisy, data) / len(batch_x)\n",
        "            else:\n",
        "                rec, _ = model(data, False)\n",
        "                loss_ae = criterion_ae(rec, data) / len(batch_x)\n",
        "\n",
        "        if mode in ['both', 'clf']:\n",
        "            rec_clean, logits = model(data, True)\n",
        "            loss_clf = criterion_clf(logits, target)\n",
        "\n",
        "        if mode == 'both':\n",
        "            loss_total = loss_ae + lam_factor*loss_clf\n",
        "            train_losses.append([loss_ae.detach().cpu().numpy(),\n",
        "                                 loss_clf.detach().cpu().numpy()])\n",
        "        elif mode == 'ae':\n",
        "            loss_total = loss_ae\n",
        "            train_losses.append([loss_ae.detach().cpu().numpy(),\n",
        "                                 0.0])\n",
        "        elif mode == 'clf':\n",
        "            loss_total = loss_clf\n",
        "            train_losses.append([0.0,\n",
        "                                 loss_clf.detach().cpu().numpy()])\n",
        "\n",
        "        loss_total.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "def test(model, criterion, test_loader,\n",
        "         eval_classifier=False, num_batch=None):\n",
        "    test_loss, n_test, correct = 0.0, 0, 0\n",
        "    all_predss=[]\n",
        "    if eval_classifier:\n",
        "        y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i,(batch_x,batch_y) in enumerate(test_loader, 1):\n",
        "            if num_batch is not None:\n",
        "                if i >= num_batch:\n",
        "                    continue\n",
        "            data = batch_x.to(device)\n",
        "            rec, logits = model(data, eval_classifier)\n",
        "\n",
        "            test_loss += criterion(rec, data).detach().cpu().numpy()\n",
        "            n_test += len(batch_x)\n",
        "            if eval_classifier:\n",
        "                proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "                preds = np.ones_like(proba, dtype=np.int32)\n",
        "                preds[proba < 0.5] = 0\n",
        "                all_predss.extend(preds)###????\n",
        "                y_arr = np.array(batch_y, dtype=np.int32)\n",
        "\n",
        "                correct += np.sum(preds == y_arr)\n",
        "                y_true.extend(y_arr.tolist())\n",
        "                y_pred.extend(proba.tolist())\n",
        "        mlp_acc,mlp_sens,mlp_spef = confusion(y_true,all_predss)\n",
        "\n",
        "    return  mlp_acc,mlp_sens,mlp_spef#,correct/n_test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLBvWm1Zje7O",
        "outputId": "7a3a0a4c-f092-4c55-92ad-b2e5dd6ecdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjxpvdXUje7P",
        "outputId": "c7c4ee3c-649d-4477-84d7-39be6529fcc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_corr:   19900\n",
            "4975\n",
            "p_bernoulli:  None\n",
            "augmentaiton:  True aug_factor:  2 num_neighbs:  5 lim4sim:  2\n",
            "use_dropout:  False \n",
            "\n",
            "(0.6741573033707865, 0.6829268292682927, 0.6666666666666666)\n",
            "(0.6629213483146067, 0.5609756097560976, 0.75)\n",
            "(0.7078651685393258, 0.6585365853658537, 0.75)\n",
            "(0.6853932584269663, 0.6341463414634146, 0.7291666666666666)\n",
            "(0.6477272727272727, 0.675, 0.625)\n",
            "(0.8295454545454546, 0.85, 0.8125)\n",
            "(0.7159090909090909, 0.6585365853658537, 0.7659574468085106)\n",
            "(0.6590909090909091, 0.43902439024390244, 0.851063829787234)\n",
            "(0.6931818181818182, 0.5609756097560976, 0.8085106382978723)\n",
            "(0.6477272727272727, 0.6585365853658537, 0.6382978723404256)\n",
            "averages:\n",
            "[0.69235189 0.63786585 0.73971631]\n",
            "308.53171253204346\n",
            "(0.7303370786516854, 0.7073170731707317, 0.75)\n",
            "(0.7752808988764045, 0.7317073170731707, 0.8125)\n",
            "(0.651685393258427, 0.5365853658536586, 0.75)\n",
            "(0.7415730337078652, 0.7073170731707317, 0.7708333333333334)\n",
            "(0.6818181818181818, 0.7, 0.6666666666666666)\n",
            "(0.7613636363636364, 0.7, 0.8125)\n",
            "(0.7159090909090909, 0.7073170731707317, 0.723404255319149)\n",
            "(0.6931818181818182, 0.6341463414634146, 0.7446808510638298)\n",
            "(0.6704545454545454, 0.5853658536585366, 0.7446808510638298)\n",
            "(0.6136363636363636, 0.5853658536585366, 0.6382978723404256)\n",
            "averages:\n",
            "[0.69793795 0.64868902 0.74053635]\n",
            "609.3772394657135\n",
            "(0.6741573033707865, 0.6097560975609756, 0.7291666666666666)\n",
            "(0.7303370786516854, 0.6097560975609756, 0.8333333333333334)\n",
            "(0.6629213483146067, 0.6097560975609756, 0.7083333333333334)\n",
            "(0.6966292134831461, 0.6097560975609756, 0.7708333333333334)\n",
            "(0.6477272727272727, 0.575, 0.7083333333333334)\n",
            "(0.6477272727272727, 0.65, 0.6458333333333334)\n",
            "(0.6931818181818182, 0.6097560975609756, 0.7659574468085106)\n",
            "(0.8068181818181818, 0.7804878048780488, 0.8297872340425532)\n",
            "(0.7272727272727273, 0.6341463414634146, 0.8085106382978723)\n",
            "(0.6363636363636364, 0.5609756097560976, 0.7021276595744681)\n",
            "averages:\n",
            "[0.69606316 0.64077236 0.74376478]\n",
            "925.04403424263\n",
            "(0.7078651685393258, 0.6341463414634146, 0.7708333333333334)\n",
            "(0.7078651685393258, 0.5609756097560976, 0.8333333333333334)\n",
            "(0.7640449438202247, 0.6341463414634146, 0.875)\n",
            "(0.6292134831460674, 0.6341463414634146, 0.625)\n",
            "(0.6363636363636364, 0.5609756097560976, 0.7021276595744681)\n",
            "(0.6931818181818182, 0.5609756097560976, 0.8085106382978723)\n",
            "(0.6590909090909091, 0.5609756097560976, 0.7446808510638298)\n",
            "(0.6818181818181818, 0.6341463414634146, 0.723404255319149)\n",
            "(0.7272727272727273, 0.8, 0.6666666666666666)\n",
            "(0.7613636363636364, 0.8, 0.7291666666666666)\n",
            "averages:\n",
            "[0.69624936 0.64009146 0.74479167]\n",
            "1241.7512073516846\n",
            "(0.7640449438202247, 0.6097560975609756, 0.8958333333333334)\n",
            "(0.6853932584269663, 0.5853658536585366, 0.7708333333333334)\n",
            "(0.7191011235955056, 0.7317073170731707, 0.7083333333333334)\n",
            "(0.6179775280898876, 0.4878048780487805, 0.7291666666666666)\n",
            "(0.75, 0.75, 0.75)\n",
            "(0.7159090909090909, 0.675, 0.75)\n",
            "(0.7727272727272727, 0.7073170731707317, 0.8297872340425532)\n",
            "(0.5909090909090909, 0.5853658536585366, 0.5957446808510638)\n",
            "(0.75, 0.7804878048780488, 0.723404255319149)\n",
            "(0.6931818181818182, 0.6097560975609756, 0.7659574468085106)\n",
            "averages:\n",
            "[0.69818437 0.64252439 0.74621454]\n",
            "1557.9171297550201\n",
            "(0.7191011235955056, 0.6829268292682927, 0.75)\n",
            "(0.7078651685393258, 0.5365853658536586, 0.8541666666666666)\n",
            "(0.6853932584269663, 0.6829268292682927, 0.6875)\n",
            "(0.6404494382022472, 0.5121951219512195, 0.75)\n",
            "(0.7159090909090909, 0.75, 0.6875)\n",
            "(0.7840909090909091, 0.725, 0.8333333333333334)\n",
            "(0.7613636363636364, 0.6829268292682927, 0.8297872340425532)\n",
            "(0.6590909090909091, 0.7073170731707317, 0.6170212765957447)\n",
            "(0.7159090909090909, 0.5853658536585366, 0.8297872340425532)\n",
            "(0.5909090909090909, 0.4878048780487805, 0.6808510638297872)\n",
            "averages:\n",
            "[0.69815501 0.64132114 0.7471779 ]\n",
            "1873.2967591285706\n",
            "(0.7078651685393258, 0.5853658536585366, 0.8125)\n",
            "(0.7078651685393258, 0.7073170731707317, 0.7083333333333334)\n",
            "(0.5955056179775281, 0.5365853658536586, 0.6458333333333334)\n",
            "(0.6966292134831461, 0.6097560975609756, 0.7708333333333334)\n",
            "(0.6363636363636364, 0.45, 0.7916666666666666)\n",
            "(0.6590909090909091, 0.5, 0.7916666666666666)\n",
            "(0.7045454545454546, 0.5853658536585366, 0.8085106382978723)\n",
            "(0.6818181818181818, 0.5365853658536586, 0.8085106382978723)\n",
            "(0.7613636363636364, 0.7560975609756098, 0.7659574468085106)\n",
            "(0.6931818181818182, 0.6341463414634146, 0.7446808510638298)\n",
            "averages:\n",
            "[0.69619327 0.63400697 0.74970238]\n",
            "2191.0551900863647\n",
            "(0.7528089887640449, 0.6097560975609756, 0.875)\n",
            "(0.6741573033707865, 0.5121951219512195, 0.8125)\n",
            "(0.6404494382022472, 0.6341463414634146, 0.6458333333333334)\n",
            "(0.6853932584269663, 0.7073170731707317, 0.6666666666666666)\n",
            "(0.6931818181818182, 0.75, 0.6458333333333334)\n",
            "(0.6704545454545454, 0.7, 0.6458333333333334)\n",
            "(0.7272727272727273, 0.6585365853658537, 0.7872340425531915)\n",
            "(0.7159090909090909, 0.6829268292682927, 0.7446808510638298)\n",
            "(0.75, 0.7073170731707317, 0.7872340425531915)\n",
            "(0.7386363636363636, 0.6829268292682927, 0.7872340425531915)\n",
            "averages:\n",
            "[0.69727241 0.63782012 0.7484652 ]\n",
            "2507.79842209816\n",
            "(0.6966292134831461, 0.5853658536585366, 0.7916666666666666)\n",
            "(0.6629213483146067, 0.6341463414634146, 0.6875)\n",
            "(0.6853932584269663, 0.4878048780487805, 0.8541666666666666)\n",
            "(0.651685393258427, 0.5853658536585366, 0.7083333333333334)\n",
            "(0.6931818181818182, 0.675, 0.7083333333333334)\n",
            "(0.7840909090909091, 0.675, 0.875)\n",
            "(0.6363636363636364, 0.5365853658536586, 0.723404255319149)\n",
            "(0.6931818181818182, 0.6585365853658537, 0.723404255319149)\n",
            "(0.7613636363636364, 0.6829268292682927, 0.8297872340425532)\n",
            "(0.625, 0.5853658536585366, 0.6595744680851063)\n",
            "averages:\n",
            "[0.69635115 0.63479675 0.74931541]\n",
            "2821.043627500534\n",
            "(0.6629213483146067, 0.5609756097560976, 0.75)\n",
            "(0.6966292134831461, 0.5609756097560976, 0.8125)\n",
            "(0.6404494382022472, 0.5609756097560976, 0.7083333333333334)\n",
            "(0.7865168539325843, 0.7804878048780488, 0.7916666666666666)\n",
            "(0.7386363636363636, 0.775, 0.7083333333333334)\n",
            "(0.6818181818181818, 0.575, 0.7708333333333334)\n",
            "(0.6363636363636364, 0.6097560975609756, 0.6595744680851063)\n",
            "(0.6818181818181818, 0.6585365853658537, 0.7021276595744681)\n",
            "(0.6363636363636364, 0.5609756097560976, 0.7021276595744681)\n",
            "(0.6818181818181818, 0.5853658536585366, 0.7659574468085106)\n",
            "averages:\n",
            "[0.69514939 0.63359756 0.7480984 ]\n",
            "3137.042725086212\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if p_Method == \"ASD-DiagNet\" and p_mode == \"whole\":\n",
        "\n",
        "    num_corr = len(all_corr[flist[0]][0])\n",
        "    print(\"num_corr:  \",num_corr)\n",
        "\n",
        "    start =time.time()\n",
        "    batch_size = 8\n",
        "    learning_rate_ae, learning_rate_clf = 0.0001, 0.0001\n",
        "    num_epochs = 25\n",
        "\n",
        "    p_bernoulli = None\n",
        "    augmentation = p_augmentation\n",
        "    use_dropout = False\n",
        "\n",
        "    aug_factor = 2\n",
        "    num_neighbs = 5\n",
        "    lim4sim = 2\n",
        "    n_lat = int(num_corr/4)\n",
        "    print(n_lat)\n",
        "    start= time.time()\n",
        "\n",
        "    print('p_bernoulli: ', p_bernoulli)\n",
        "    print('augmentaiton: ', augmentation, 'aug_factor: ', aug_factor,\n",
        "          'num_neighbs: ', num_neighbs, 'lim4sim: ', lim4sim)\n",
        "    print('use_dropout: ', use_dropout, '\\n')\n",
        "\n",
        "\n",
        "    sim_function = functools.partial(cal_similarity, lim=lim4sim)\n",
        "    crossval_res_kol=[]\n",
        "    y_arr = np.array([get_label(f) for f in flist])\n",
        "    flist = np.array(flist)\n",
        "    kk=0\n",
        "    for rp in range(10):\n",
        "        kf = StratifiedKFold(n_splits=p_fold, random_state=1, shuffle=True)\n",
        "        np.random.shuffle(flist)\n",
        "        y_arr = np.array([get_label(f) for f in flist])\n",
        "        for kk,(train_index, test_index) in enumerate(kf.split(flist, y_arr)):\n",
        "            train_samples, test_samples = flist[train_index], flist[test_index]\n",
        "\n",
        "\n",
        "            verbose = (True if (kk == 0) else False)\n",
        "\n",
        "            regions_inds = get_regs(train_samples,int(num_corr/4))\n",
        "\n",
        "            num_inpp = len(regions_inds)\n",
        "            n_lat = int(num_inpp/2)\n",
        "            train_loader=get_loader(data=all_corr, samples_list=train_samples,\n",
        "                                    batch_size=batch_size, mode='train',\n",
        "                                    augmentation=augmentation, aug_factor=aug_factor,\n",
        "                                    num_neighbs=num_neighbs, eig_data=eig_data, similarity_fn=sim_function,\n",
        "                                    verbose=verbose,regions=regions_inds)\n",
        "\n",
        "            test_loader=get_loader(data=all_corr, samples_list=test_samples,\n",
        "                                   batch_size=batch_size, mode='test', augmentation=False,\n",
        "                                   verbose=verbose,regions=regions_inds)\n",
        "\n",
        "            model = MTAutoEncoder(tied=True, num_inputs=num_inpp, num_latent=n_lat, use_dropout=use_dropout)\n",
        "            model.to(device)\n",
        "            criterion_ae = nn.MSELoss(reduction='sum')\n",
        "            criterion_clf = nn.BCEWithLogitsLoss()\n",
        "            optimizer = optim.SGD([{'params': model.fc_encoder.parameters(), 'lr': learning_rate_ae},\n",
        "                                   {'params': model.classifier.parameters(), 'lr': learning_rate_clf}],\n",
        "                                  momentum=0.9)\n",
        "\n",
        "            for epoch in range(1, num_epochs+1):\n",
        "                if epoch <= 20:\n",
        "                    train_losses = train(model, epoch, train_loader, p_bernoulli, mode='both')\n",
        "                else:\n",
        "                    train_losses = train(model, epoch, train_loader, p_bernoulli, mode='clf')\n",
        "\n",
        "\n",
        "            res_mlp = test(model, criterion_ae, test_loader, eval_classifier=True)\n",
        "            print(test(model, criterion_ae, test_loader, eval_classifier=True))\n",
        "            crossval_res_kol.append(res_mlp)\n",
        "        print(\"averages:\")\n",
        "        print(np.mean(np.array(crossval_res_kol),axis = 0))\n",
        "        finish= time.time()\n",
        "\n",
        "        print(finish-start)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calculate overall averages across all repeats\n",
        "all_averages = [\n",
        "    [0.69235189, 0.63786585, 0.73971631],\n",
        "    [0.69793795, 0.64868902, 0.74053635],\n",
        "    [0.69606316, 0.64077236, 0.74376478],\n",
        "    [0.69624936, 0.64009146, 0.74479167],\n",
        "    [0.69818437, 0.64252439, 0.74621454],\n",
        "    [0.69815501, 0.64132114, 0.7471779],\n",
        "    [0.69619327, 0.63400697, 0.74970238],\n",
        "    [0.69727241, 0.63782012, 0.7484652],\n",
        "    [0.69635115, 0.63479675, 0.74931541],\n",
        "    [0.69514939, 0.63359756, 0.7480984]\n",
        "]\n",
        "\n",
        "final_averages = np.mean(all_averages, axis=0)\n",
        "\n",
        "# Create Table 2 equivalent\n",
        "results_dict = {\n",
        "    'Method': ['ASD-DiagNet', 'ASD-DiagNet (no aug.)', 'SVM', 'Random forest', 'Heinsfeld et al.'],\n",
        "    'Accuracy': [final_averages[0], None, None, None, None],  # Fill in other methods' results when available\n",
        "    'Sensitivity': [final_averages[1], None, None, None, None],\n",
        "    'Specificity': [final_averages[2], None, None, None, None]\n",
        "}\n",
        "\n",
        "# Create visualization code\n",
        "def create_results_table():\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Create table data\n",
        "    cell_text = []\n",
        "    for method, acc, sens, spec in zip(\n",
        "        results_dict['Method'],\n",
        "        results_dict['Accuracy'],\n",
        "        results_dict['Sensitivity'],\n",
        "        results_dict['Specificity']\n",
        "    ):\n",
        "        if acc is not None:\n",
        "            cell_text.append([method, f\"{acc:.1f}\", f\"{sens:.1f}\", f\"{spec:.1f}\"])\n",
        "        else:\n",
        "            cell_text.append([method, \"-\", \"-\", \"-\"])\n",
        "\n",
        "    # Create table\n",
        "    table = plt.table(\n",
        "        cellText=cell_text,\n",
        "        colLabels=['Method', 'Accuracy', 'Sensitivity', 'Specificity'],\n",
        "        loc='center',\n",
        "        cellLoc='center',\n",
        "        colWidths=[0.4, 0.2, 0.2, 0.2]\n",
        "    )\n",
        "\n",
        "    # Style the table\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(9)\n",
        "    table.scale(1.2, 1.5)\n",
        "\n",
        "    # Add title\n",
        "    plt.title('Classification Performance using 10-fold Cross-validation', pad=20)\n",
        "    plt.show()\n",
        "\n",
        "# Create plot\n",
        "create_results_table()\n",
        "\n",
        "print(\"\\nNumerical Results:\")\n",
        "print(f\"Final Average Accuracy: {final_averages[0]*100:.1f}%\")\n",
        "print(f\"Final Average Sensitivity: {final_averages[1]*100:.1f}%\")\n",
        "print(f\"Final Average Specificity: {final_averages[2]*100:.1f}%\")"
      ],
      "metadata": {
        "id": "Y8osh-Q5guEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "7d7f8ba2-bf54-4cd2-8414-f12ff7928355"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numerical Results:\n",
            "Final Average Accuracy: 69.6%\n",
            "Final Average Sensitivity: 63.9%\n",
            "Final Average Specificity: 74.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wTmDvXsD2kIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1oKImd8Eje7P"
      },
      "outputs": [],
      "source": [
        "#DON'T RUN!!!\n",
        "#p_mode = \"perceter\"\n",
        "if p_Method == \"ASD-DiagNet\" and p_mode == \"percenter\":\n",
        "    num_corr = len(all_corr[flist[0]][0])\n",
        "\n",
        "    flist = os.listdir(data_main_path)\n",
        "\n",
        "    for f in range(len(flist)):\n",
        "        flist[f] = get_key(flist[f])\n",
        "\n",
        "    centers_dict = {}\n",
        "    for f in flist:\n",
        "        key = f.split('_')[0]\n",
        "\n",
        "        if key not in centers_dict:\n",
        "            centers_dict[key] = []\n",
        "        centers_dict[key].append(f)\n",
        "\n",
        "\n",
        "\n",
        "    flist = np.array(centers_dict[p_center])\n",
        "\n",
        "    start =time.time()\n",
        "    #flist = np.array(sorted(os.listdir(data_main_path)))\n",
        "    batch_size = 8\n",
        "    learning_rate_ae, learning_rate_clf = 0.0001, 0.0001\n",
        "    num_epochs = 25\n",
        "\n",
        "    p_bernoulli = None\n",
        "    augmentation = p_augmentation\n",
        "    use_dropout = False\n",
        "\n",
        "    aug_factor = 2\n",
        "    num_neighbs = 5\n",
        "    lim4sim = 2\n",
        "    n_lat = int(num_corr/4)\n",
        "\n",
        "\n",
        "    print('p_bernoulli: ', p_bernoulli)\n",
        "    print('augmentaiton: ', augmentation, 'aug_factor: ', aug_factor,\n",
        "          'num_neighbs: ', num_neighbs, 'lim4sim: ', lim4sim)\n",
        "    print('use_dropout: ', use_dropout, '\\n')\n",
        "\n",
        "\n",
        "    sim_function = functools.partial(cal_similarity, lim=lim4sim)\n",
        "    all_rp_res=[]\n",
        "    y_arr = np.array([get_label(f) for f in flist])\n",
        "\n",
        "    kk=0\n",
        "    crossval_res_kol_kol=[]\n",
        "    for rp in range(10):\n",
        "        print(\"========================\")\n",
        "        crossval_res_kol = []\n",
        "        start= time.time()\n",
        "        kf = StratifiedKFold(n_splits=p_fold)\n",
        "        #np.random.shuffle(flist)\n",
        "        y_arr = np.array([get_label(f) for f in flist])\n",
        "        for kk,(train_index, test_index) in enumerate(kf.split(flist, y_arr)):\n",
        "\n",
        "            train_samples, test_samples = flist[train_index], flist[test_index]\n",
        "\n",
        "            verbose = (True if (kk == 0) else False)\n",
        "\n",
        "            regions_inds = get_regs(train_samples,int(num_corr/4))\n",
        "            num_inpp = len(regions_inds)\n",
        "            n_lat = int(num_inpp/2)\n",
        "            num_inpp = len(regions_inds)\n",
        "            train_loader=get_loader(data=all_corr, samples_list=train_samples,\n",
        "                                    batch_size=batch_size, mode='train',\n",
        "                                    augmentation=augmentation, aug_factor=aug_factor,\n",
        "                                    num_neighbs=num_neighbs, eig_data=eig_data, similarity_fn=sim_function,\n",
        "                                    verbose=verbose,regions=regions_inds)\n",
        "\n",
        "            test_loader=get_loader(data=all_corr, samples_list=test_samples,\n",
        "                                   batch_size=batch_size, mode='test', augmentation=False,\n",
        "                                   verbose=verbose,regions=regions_inds)\n",
        "\n",
        "            model = MTAutoEncoder(tied=True, num_inputs=num_inpp, num_latent=n_lat, use_dropout=use_dropout)\n",
        "            model.to(device)\n",
        "            criterion_ae = nn.MSELoss(reduction='sum')\n",
        "            criterion_clf = nn.BCEWithLogitsLoss()\n",
        "            optimizer = optim.SGD([{'params': model.fc_encoder.parameters(), 'lr': learning_rate_ae},\n",
        "                                   {'params': model.classifier.parameters(), 'lr': learning_rate_clf}],\n",
        "                                  momentum=0.9)\n",
        "\n",
        "            for epoch in range(1, num_epochs+1):\n",
        "                if epoch <= 20:\n",
        "                    train_losses = train(model, epoch, train_loader, p_bernoulli, mode='both')\n",
        "                else:\n",
        "                    train_losses = train(model, epoch, train_loader, p_bernoulli, mode='clf')\n",
        "\n",
        "\n",
        "            res_mlp = test(model, criterion_ae, test_loader, eval_classifier=True)\n",
        "            #print(\"fold\",kk+1,\":\",test(model, criterion_ae, test_loader, eval_classifier=True))\n",
        "            crossval_res_kol.append(res_mlp)\n",
        "        print(\"Result of repeat \",rp,\":\")\n",
        "        print(np.mean(np.array(crossval_res_kol),axis = 0))\n",
        "        all_rp_res.append(np.mean(np.array(crossval_res_kol),axis = 0))\n",
        "        finish= time.time()\n",
        "\n",
        "        print(\"Running time:\",finish-start)\n",
        "    print(\"Avergae result of 10 repeats: \",np.mean(np.array(all_rp_res),axis = 0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DON'T RUN!!!\n",
        "if p_Method != \"ASD-DiagNet\" and p_mode == \"whole\":\n",
        "\n",
        "    clf = SVC(gamma = 'auto') if  p_Method == 'SVM' else RandomForestClassifier(n_estimators=100)\n",
        "    overall_result = []\n",
        "    for rp in range(10):\n",
        "        kf = StratifiedKFold(n_splits=p_fold, random_state=1, shuffle=True)\n",
        "        np.random.shuffle(flist)\n",
        "        y_arr = np.array([get_label(f) for f in flist])\n",
        "        res = []\n",
        "        for kk,(train_index, test_index) in enumerate(kf.split(flist, y_arr)):\n",
        "            train_samples, test_samples = np.array(flist)[train_index], np.array(flist)[test_index]\n",
        "            train_data = []\n",
        "            train_labels = []\n",
        "            test_data = []\n",
        "            test_labels = []\n",
        "\n",
        "            for i in train_samples:\n",
        "                train_data.append(all_corr[i][0])\n",
        "                train_labels.append(all_corr[i][1])\n",
        "\n",
        "            for i in test_samples:\n",
        "                test_data.append(all_corr[i][0])\n",
        "                test_labels.append(all_corr[i][1])\n",
        "\n",
        "\n",
        "            clf.fit(train_data,train_labels)\n",
        "            pr = clf.predict(test_data)\n",
        "            res.append(confusion(test_labels,pr))\n",
        "\n",
        "        print(\"repeat: \",rp,np.mean(res, axis=0).tolist())\n",
        "        overall_result.append(np.mean(res, axis=0).tolist())\n",
        "    print(\"---------------Result of repeating 10 times-------------------\")\n",
        "    print(np.mean(np.array(overall_result), axis=0).tolist())"
      ],
      "metadata": {
        "id": "WIhp553kjEPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MYjNXz4je7P"
      },
      "outputs": [],
      "source": [
        "#DON'T RUN!!!\n",
        "random.seed(19)\n",
        "np.random.seed(19)\n",
        "if p_Method != \"ASD-DiagNet\" and p_mode == \"percenter\":\n",
        "\n",
        "    clf = SVC(gamma = 'auto') if  p_Method == 'SVM' else RandomForestClassifier(n_estimators=100)\n",
        "    overall_result = []\n",
        "    for rp in range(10):\n",
        "        kf = StratifiedKFold(n_splits=p_fold, random_state=1, shuffle=True)\n",
        "        np.random.shuffle(flist)\n",
        "        y_arr = np.array([get_label(f) for f in flist])\n",
        "        res = []\n",
        "        for kk,(train_index, test_index) in enumerate(kf.split(flist, y_arr)):\n",
        "            train_samples, test_samples = np.array(flist)[train_index], np.array(flist)[test_index]\n",
        "            train_data = []\n",
        "            train_labels = []\n",
        "            test_data = []\n",
        "            test_labels = []\n",
        "\n",
        "            for i in train_samples:\n",
        "                train_data.append(all_corr[i][0])\n",
        "                train_labels.append(all_corr[i][1])\n",
        "\n",
        "            for i in test_samples:\n",
        "                test_data.append(all_corr[i][0])\n",
        "                test_labels.append(all_corr[i][1])\n",
        "\n",
        "            clf.fit(train_data,train_labels)\n",
        "            pr = clf.predict(test_data)\n",
        "            res.append(confusion(test_labels,pr))\n",
        "\n",
        "        print(\"repeat: \",rp,np.mean(res, axis=0).tolist())\n",
        "        overall_result.append(np.mean(res, axis=0).tolist())\n",
        "    print(\"---------------Result of repeating 10 times for: \",p_center,\"-------------------\")\n",
        "    print(np.mean(np.array(overall_result), axis=0).tolist())"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}