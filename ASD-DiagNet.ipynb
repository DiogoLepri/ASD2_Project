{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiogoLepri/ASD2_Project/blob/main/ASD-DiagNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mVAfnd06ES9",
        "outputId": "ed79435b-6e17-47bd-a9bb-192fdb888434"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ASD2_Project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnJkylVA6DuC",
        "outputId": "c738e4d4-c50f-4f74-9daa-e5fdd51fc9d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ASD2_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib scikit-learn torch pyprind scipy\n"
      ],
      "metadata": {
        "id": "n0I3QvBKj_lM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ade014-35a2-4715-da2a-41813498dc96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyprind-2.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "parameters"
        ],
        "id": "IF69HS76je7I"
      },
      "outputs": [],
      "source": [
        "#options: cc200, dosenbach160, aal\n",
        "p_ROI = \"cc200\"\n",
        "p_fold = 10\n",
        "p_center = \"Stanford\"\n",
        "p_mode = \"whole\"\n",
        "p_augmentation = True\n",
        "p_Method = \"ASD-DiagNet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1Oc4GXGje7K",
        "outputId": "25e7d2e4-73db-468a-94c7-77609d0eb52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****List of patameters****\n",
            "ROI atlas:  cc200\n",
            "per Center or whole:  whole\n",
            "Method's name:  ASD-DiagNet\n",
            "Augmentation:  True\n"
          ]
        }
      ],
      "source": [
        "parameter_list = [p_ROI,p_fold,p_center,p_mode,p_augmentation,p_Method]\n",
        "print(\"*****List of patameters****\")\n",
        "print(\"ROI atlas: \",p_ROI)\n",
        "print(\"per Center or whole: \",p_mode)\n",
        "if p_mode == 'percenter':\n",
        "    print(\"Center's name: \",p_center)\n",
        "print(\"Method's name: \",p_Method)\n",
        "if p_Method == \"ASD-DiagNet\":\n",
        "    print(\"Augmentation: \",p_augmentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jUGCxT3qje7L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from functools import reduce\n",
        "from sklearn.impute import SimpleImputer\n",
        "import time\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import pyprind\n",
        "import sys\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy import stats\n",
        "from sklearn import tree\n",
        "import functools\n",
        "import numpy.ma as ma # for masked arrays\n",
        "import pyprind\n",
        "import random\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7-Rr-nGje7L"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bp8xZtF5je7M"
      },
      "outputs": [],
      "source": [
        "def get_key(filename):\n",
        "    f_split = filename.split('_')\n",
        "    if f_split[3] == 'rois':\n",
        "        key = '_'.join(f_split[0:3])\n",
        "    else:\n",
        "        key = '_'.join(f_split[0:2])\n",
        "    return key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_main_path = f'/content/drive/MyDrive/ASD2_Project/Outputs/cpac/filt_global/rois_{p_ROI}'\n",
        "flist = os.listdir(data_main_path)\n",
        "print(len(flist))\n",
        "\n",
        "for f in range(len(flist)):\n",
        "    flist[f] = get_key(flist[f])\n",
        "\n",
        "\n",
        "df_labels = pd.read_csv('/content/drive/MyDrive/ASD2_Project/Phenotypic_V1_0b_preprocessed1.csv')\n",
        "df_labels.DX_GROUP = df_labels.DX_GROUP.map({1: 1, 2: 0})\n",
        "print(len(df_labels))\n",
        "\n",
        "labels = {}\n",
        "for i, row in df_labels.iterrows():\n",
        "    file_id = row['FILE_ID']\n",
        "    y_label = row['DX_GROUP']\n",
        "    if file_id == 'no_filename':\n",
        "        continue\n",
        "    assert(file_id not in labels)\n",
        "    labels[file_id] = y_label\n",
        "\n",
        "#new age\n",
        "df_labels['AGE_AT_SCAN'] = df_labels['AGE_AT_SCAN'].astype(np.float32)\n",
        "ages = df_labels['AGE_AT_SCAN']\n",
        "ages_norm = ((ages - ages.mean()) / ages.std()).round(1)\n",
        "\n",
        "phen_dict = {}\n",
        "for i, row in df_labels.iterrows():\n",
        "    file_id = row['FILE_ID']\n",
        "    if file_id == 'no_filename':\n",
        "        continue\n",
        "    phen_dict[file_id] = [ages_norm.iloc[i]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40VjQNF33Yie",
        "outputId": "bb47336d-ec9d-4972-fd8a-a14cca857a1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "884\n",
            "1112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions for computing correlations\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wq2mKIRWb-vH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a7y4oZhgje7M"
      },
      "outputs": [],
      "source": [
        "def get_label(filename):\n",
        "    assert (filename in labels)\n",
        "    return labels[filename]\n",
        "\n",
        "\n",
        "def get_corr_data(filename):\n",
        "    #print(filename)\n",
        "    for file in os.listdir(data_main_path):\n",
        "        if file.startswith(filename):\n",
        "            df = pd.read_csv(os.path.join(data_main_path, file), sep='\\t')\n",
        "\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        corr = np.nan_to_num(np.corrcoef(df.T))\n",
        "        mask = np.invert(np.tri(corr.shape[0], k=-1, dtype=bool))\n",
        "        m = ma.masked_where(mask == 1, mask)\n",
        "        return ma.masked_where(m, corr).compressed()\n",
        "\n",
        "def get_corr_matrix(filename):\n",
        "    for file in os.listdir(data_main_path):\n",
        "        if file.startswith(filename):\n",
        "            df = pd.read_csv(os.path.join(data_main_path, file), sep='\\t')\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        corr = np.nan_to_num(np.corrcoef(df.T))\n",
        "        return corr\n",
        "\n",
        "def confusion(g_turth,predictions):\n",
        "    tn, fp, fn, tp = confusion_matrix(g_turth,predictions).ravel()\n",
        "    accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
        "    sensitivity = (tp)/(tp+fn)\n",
        "    specificty = (tn)/(tn+fp)\n",
        "    return accuracy,sensitivity,specificty\n",
        "\n",
        "def get_regs(samplesnames,regnum):\n",
        "    datas = []\n",
        "    for sn in samplesnames:\n",
        "        datas.append(all_corr[sn][0])\n",
        "    datas = np.array(datas)\n",
        "    avg=[]\n",
        "    for ie in range(datas.shape[1]):\n",
        "        avg.append(np.mean(datas[:,ie]))\n",
        "    avg=np.array(avg)\n",
        "    highs=avg.argsort()[-regnum:][::-1]\n",
        "    lows=avg.argsort()[:regnum][::-1]\n",
        "    regions=np.concatenate((highs,lows),axis=0)\n",
        "    return regions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_df_Lrp8je7M"
      },
      "source": [
        "## Helper fnuctions for computing correlations (Step A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_980i7pjje7N"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('./Outputs/correlations_file'+p_ROI+'.pkl'):\n",
        "    pbar=pyprind.ProgBar(len(flist))\n",
        "    all_corr = {}\n",
        "    for f in flist:\n",
        "\n",
        "        lab = get_label(f)\n",
        "        all_corr[f] = (get_corr_data(f), lab)\n",
        "        pbar.update()\n",
        "\n",
        "    print('Corr-computations finished')\n",
        "\n",
        "    pickle.dump(all_corr, open('./Outputs/correlations_file'+p_ROI+'.pkl', 'wb'))\n",
        "    print('Saving to file finished')\n",
        "\n",
        "else:\n",
        "    all_corr = pickle.load(open('./Outputs/correlations_file'+p_ROI+'.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vFuNrLsje7N"
      },
      "source": [
        "## Computing eigenvalues and eigenvector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Putbeqefje7N",
        "outputId": "4adbe101-a41b-4ccb-a0db-5a26cb54230d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:02:13\n"
          ]
        }
      ],
      "source": [
        "if p_Method==\"ASD-DiagNet\":\n",
        "    eig_data = {}\n",
        "    pbar = pyprind.ProgBar(len(flist))\n",
        "    for f in flist:\n",
        "        d = get_corr_matrix(f)\n",
        "        eig_vals, eig_vecs = np.linalg.eig(d)\n",
        "\n",
        "        for ev in eig_vecs.T:\n",
        "            np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
        "\n",
        "        sum_eigvals = np.sum(np.abs(eig_vals))\n",
        "        # Make a list of (eigenvalue, eigenvector, norm_eigval) tuples\n",
        "        eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i], np.abs(eig_vals[i])/sum_eigvals)\n",
        "                     for i in range(len(eig_vals))]\n",
        "\n",
        "        # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
        "        eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        eig_data[f] = {'eigvals':np.array([ep[0] for ep in eig_pairs]),\n",
        "                       'norm-eigvals':np.array([ep[2] for ep in eig_pairs]),\n",
        "                       'eigvecs':[ep[1] for ep in eig_pairs]}\n",
        "        pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mUbBcVXje7N"
      },
      "source": [
        "## Calculating Eros similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y9GN9yITje7N"
      },
      "outputs": [],
      "source": [
        "def norm_weights(sub_flist):\n",
        "    num_dim = len(eig_data[flist[0]]['eigvals'])\n",
        "    norm_weights = np.zeros(shape=num_dim)\n",
        "    for f in sub_flist:\n",
        "        norm_weights += eig_data[f]['norm-eigvals']\n",
        "    return norm_weights\n",
        "\n",
        "def cal_similarity(d1, d2, weights, lim=None):\n",
        "    res = 0.0\n",
        "    if lim is None:\n",
        "        weights_arr = weights.copy()\n",
        "    else:\n",
        "        weights_arr = weights[:lim].copy()\n",
        "        weights_arr /= np.sum(weights_arr)\n",
        "    for i,w in enumerate(weights_arr):\n",
        "        res += w*np.inner(d1[i], d2[i])\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmfYEmZije7N"
      },
      "source": [
        "## Defining dataset class (Step B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aiJEROcRje7N"
      },
      "outputs": [],
      "source": [
        "class CC200Dataset(Dataset):\n",
        "    def __init__(self, pkl_filename=None, data=None, samples_list=None,\n",
        "                 phenotype_data=None,#new\n",
        "                 augmentation=False, aug_factor=1, num_neighbs=5,\n",
        "                 eig_data=None, similarity_fn=None, verbose=False, regs=None):\n",
        "        self.regs = regs\n",
        "        self.phenotype_data = phenotype_data  #new\n",
        "        if pkl_filename is not None:\n",
        "            if verbose:\n",
        "                print('Loading ..!', end=' ')\n",
        "            self.data = pickle.load(open(pkl_filename, 'rb'))\n",
        "        elif data is not None:\n",
        "            self.data = data.copy()\n",
        "        else:\n",
        "            sys.stderr.write('Either PKL file or data is needed!')\n",
        "            return\n",
        "\n",
        "        #if verbose:\n",
        "        #    print ('Preprocess..!', end='  ')\n",
        "        if samples_list is None:\n",
        "            self.flist = [f for f in self.data]\n",
        "        else:\n",
        "            self.flist = [f for f in samples_list]\n",
        "        self.labels = np.array([self.data[f][1] for f in self.flist])\n",
        "\n",
        "        current_flist = np.array(self.flist.copy())\n",
        "        current_lab0_flist = current_flist[self.labels == 0]\n",
        "        current_lab1_flist = current_flist[self.labels == 1]\n",
        "        #if verbose:\n",
        "        #    print(' Num Positive : ', len(current_lab1_flist), end=' ')\n",
        "        #    print(' Num Negative : ', len(current_lab0_flist), end=' ')\n",
        "\n",
        "\n",
        "        if augmentation:\n",
        "            self.num_data = aug_factor * len(self.flist)\n",
        "            self.neighbors = {}\n",
        "            pbar = pyprind.ProgBar(len(self.flist))\n",
        "            weights = norm_weights(samples_list)#??\n",
        "            for f in self.flist:\n",
        "                label = self.data[f][1]\n",
        "                candidates = (set(current_lab0_flist) if label == 0 else set(current_lab1_flist))\n",
        "                candidates.remove(f)\n",
        "                eig_f = eig_data[f]['eigvecs']\n",
        "                sim_list = []\n",
        "                for cand in candidates:\n",
        "                    eig_cand = eig_data[cand]['eigvecs']\n",
        "                    sim = similarity_fn(eig_f, eig_cand, weights)\n",
        "                    sim_list.append((sim, cand))\n",
        "                sim_list.sort(key=lambda x: x[0], reverse=True)\n",
        "                self.neighbors[f] = [item[1] for item in sim_list[:num_neighbs]]#list(candidates)#[item[1] for item in sim_list[:num_neighbs]]\n",
        "\n",
        "        else:\n",
        "            self.num_data = len(self.flist)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index < len(self.flist):\n",
        "            fname = self.flist[index]\n",
        "            data = self.data[fname][0].copy() #get_corr_data(fname, mode=cal_mode)\n",
        "            data = data[self.regs].copy()\n",
        "            label = (self.labels[index],)\n",
        "\n",
        "            #new\n",
        "            if self.phenotype_data is not None:\n",
        "                # Retrieve phenotype data using the file identifier as key\n",
        "                pheno_vals = self.phenotype_data[fname]\n",
        "                return torch.FloatTensor(data), torch.FloatTensor(pheno_vals), torch.FloatTensor(label)\n",
        "            else:\n",
        "                return torch.FloatTensor(data), torch.FloatTensor(label)\n",
        "\n",
        "        else:\n",
        "            f1 = self.flist[index % len(self.flist)]\n",
        "            d1, y1 = self.data[f1][0], self.data[f1][1]\n",
        "            d1=d1[self.regs]\n",
        "            if len(self.neighbors[f1]) > 0:#new\n",
        "                f2 = np.random.choice(self.neighbors[f1])\n",
        "            else:\n",
        "                f2 = f1  # fallback to self if no neighbors exist\n",
        "            d2, y2 = self.data[f2][0], self.data[f2][1]\n",
        "            d2 = d2[self.regs]\n",
        "            assert y1 == y2\n",
        "            r = np.random.uniform(low=0, high=1)\n",
        "            label = (y1,)\n",
        "            data = r * d1 + (1 - r) * d2\n",
        "\n",
        "            #new check---------\n",
        "            if self.phenotype_data is not None:\n",
        "                # Use phenotype from the first sample for the augmented data\n",
        "                pheno_vals = self.phenotype_data[f1]\n",
        "                return torch.FloatTensor(data), torch.FloatTensor(pheno_vals), torch.FloatTensor(label)\n",
        "            else:\n",
        "                return torch.FloatTensor(data), torch.FloatTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfUMb1Z2je7O"
      },
      "source": [
        "## Definig data loader function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GlGMx4Lrje7O"
      },
      "outputs": [],
      "source": [
        "def get_loader(pkl_filename=None, data=None, samples_list=None,\n",
        "               batch_size=64,\n",
        "               num_workers=1, mode='train',\n",
        "               *, augmentation=False, aug_factor=1, num_neighbs=5,\n",
        "               eig_data=None, similarity_fn=None, verbose=False, regions=None,\n",
        "               phenotype_data=None):  #new pheno data\n",
        "    \"\"\"Build and return data loader.\"\"\"\n",
        "    if mode == 'train':\n",
        "        shuffle = True\n",
        "    else:\n",
        "        shuffle = False\n",
        "        augmentation = False\n",
        "\n",
        "    dataset = CC200Dataset(pkl_filename=pkl_filename, data=data, samples_list=samples_list,\n",
        "                           augmentation=augmentation, aug_factor=aug_factor,\n",
        "                           eig_data=eig_data, similarity_fn=similarity_fn, verbose=verbose, regs=regions,\n",
        "                           phenotype_data=phenotype_data)  #new pheno data\n",
        "\n",
        "    data_loader = DataLoader(dataset,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=shuffle,\n",
        "                             num_workers=num_workers)\n",
        "\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK8W0nMSje7O"
      },
      "source": [
        "## Defining Autoencoder class (Step C & D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1pd8JMdje7O",
        "outputId": "597eb966-335c-4d76-92aa-1e618235eabc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAutoEncoder(\n",
              "  (fc_encoder): Linear(in_features=990, out_features=200, bias=True)\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=201, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "class MTAutoEncoder(nn.Module):\n",
        "    def __init__(self, num_inputs=990,\n",
        "                 num_latent=200, tied=True,\n",
        "                 num_classes=2, use_dropout=False):\n",
        "        super(MTAutoEncoder, self).__init__()\n",
        "        self.tied = tied\n",
        "        self.num_latent = num_latent\n",
        "\n",
        "        self.fc_encoder = nn.Linear(num_inputs, num_latent)\n",
        "\n",
        "        if not tied:\n",
        "            self.fc_decoder = nn.Linear(num_latent, num_inputs)\n",
        "\n",
        "\n",
        "        if use_dropout:\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Dropout(p=0.5),\n",
        "                nn.Linear(self.num_latent + 1, 1)#new +1,1\n",
        "            )\n",
        "        else:\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Linear(self.num_latent + 1, 1)#new +1,1\n",
        "            )\n",
        "\n",
        "    def forward(self, x, pheno_data=None, eval_classifier=False):\n",
        "      x = self.fc_encoder(x)\n",
        "      x = torch.tanh(x)\n",
        "      if eval_classifier:\n",
        "          pheno_data = pheno_data.to(x.device)\n",
        "          combined = torch.cat((x, pheno_data), dim=1)\n",
        "          x_logit = self.classifier(combined)\n",
        "      else:\n",
        "          x_logit = None\n",
        "\n",
        "      if self.tied:\n",
        "          x = F.linear(x, self.fc_encoder.weight.t())\n",
        "      else:\n",
        "          x = self.fc_decoder(x)\n",
        "\n",
        "      return x, x_logit\n",
        "\n",
        "\n",
        "mtae = MTAutoEncoder()\n",
        "mtae\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLxPmE4kje7O"
      },
      "source": [
        "## Defining training and testing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Glfo2XVQje7O"
      },
      "outputs": [],
      "source": [
        "def train(model, epoch, train_loader, p_bernoulli=None, mode='both', lam_factor=1.0):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "\n",
        "    for i, (images, pheno_data, batch_y) in enumerate(train_loader):#new before batch_x now = images\n",
        "        if len(images) != batch_size:\n",
        "            continue\n",
        "\n",
        "        if p_bernoulli is not None:\n",
        "            if i == 0:\n",
        "                p_tensor = torch.ones_like(images).to(device) * p_bernoulli\n",
        "            rand_bernoulli = torch.bernoulli(p_tensor).to(device)\n",
        "\n",
        "        images = images.to(device)\n",
        "        pheno_data = pheno_data.to(device)#new\n",
        "        batch_y = batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if mode in ['both', 'ae']:\n",
        "            if p_bernoulli is not None:\n",
        "                rec_noisy, _ = model(images * rand_bernoulli, pheno_data, False)#new\n",
        "                loss_ae = criterion_ae(rec_noisy, images) / len(images)\n",
        "            else:\n",
        "                rec, _ = model(images, pheno_data, False)#new\n",
        "                loss_ae = criterion_ae(rec, images) / len(images)\n",
        "\n",
        "        if mode in ['both', 'clf']:\n",
        "            rec_clean, logits = model(images, pheno_data, True)#new\n",
        "            loss_clf = criterion_clf(logits, batch_y)\n",
        "\n",
        "        if mode == 'both':\n",
        "            loss_total = loss_ae + lam_factor * loss_clf\n",
        "            train_losses.append([loss_ae.detach().cpu().numpy(), loss_clf.detach().cpu().numpy()])\n",
        "        elif mode == 'ae':\n",
        "            loss_total = loss_ae\n",
        "            train_losses.append([loss_ae.detach().cpu().numpy(), 0.0])\n",
        "        elif mode == 'clf':\n",
        "            loss_total = loss_clf\n",
        "            train_losses.append([0.0, loss_clf.detach().cpu().numpy()])\n",
        "\n",
        "        loss_total.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "def test(model, criterion, test_loader,\n",
        "         eval_classifier=False, num_batch=None):\n",
        "    test_loss, n_test, correct = 0.0, 0, 0\n",
        "    all_predss = []\n",
        "    if eval_classifier:\n",
        "        y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for i, (images, pheno_data, batch_y) in enumerate(test_loader, 1):#new\n",
        "            if num_batch is not None and i >= num_batch:\n",
        "                continue\n",
        "            images = images.to(device)\n",
        "            pheno_data_data = pheno_data.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            rec, logits = model(images, pheno_data, eval_classifier)\n",
        "            test_loss += criterion(rec, images).detach().cpu().numpy()\n",
        "            n_test += len(images)\n",
        "            if eval_classifier:\n",
        "                proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "                preds = np.ones_like(proba, dtype=np.int32)\n",
        "                preds[proba < 0.5] = 0\n",
        "                all_predss.extend(preds)\n",
        "                y_arr = batch_y.cpu().numpy().astype(np.int32)\n",
        "                correct += np.sum(preds == y_arr)\n",
        "                y_true.extend(y_arr.tolist())\n",
        "                y_pred.extend(proba.tolist())\n",
        "        if eval_classifier:\n",
        "            mlp_acc, mlp_sens, mlp_spef = confusion(y_true, all_predss)\n",
        "    return mlp_acc, mlp_sens, mlp_spef\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLBvWm1Zje7O",
        "outputId": "9afb78b0-5502-4079-f2b1-325b4bdb5731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bjxpvdXUje7P"
      },
      "outputs": [],
      "source": [
        "if p_Method == \"ASD-DiagNet\" and p_mode == \"whole\":\n",
        "    num_corr = len(all_corr[flist[0]][0])\n",
        "    print(\"num_corr:  \", num_corr)\n",
        "\n",
        "    start = time.time()\n",
        "    batch_size = 8\n",
        "    learning_rate_ae, learning_rate_clf = 0.0001, 0.0001\n",
        "    num_epochs = 25\n",
        "\n",
        "    p_bernoulli = None\n",
        "    augmentation = p_augmentation\n",
        "    use_dropout = False\n",
        "\n",
        "    aug_factor = 2\n",
        "    num_neighbs = 5\n",
        "    lim4sim = 2\n",
        "    n_lat = int(num_corr / 4)\n",
        "    print(\"Initial n_lat:\", n_lat)\n",
        "    start = time.time()\n",
        "\n",
        "    print('p_bernoulli:', p_bernoulli)\n",
        "    print('augmentation:', augmentation, 'aug_factor:', aug_factor,\n",
        "          'num_neighbs:', num_neighbs, 'lim4sim:', lim4sim)\n",
        "    print('use_dropout:', use_dropout, '\\n')\n",
        "\n",
        "    # Check if phenotypic data is available and optionally print a sample vector.\n",
        "    if len(phen_dict) > 0:\n",
        "        sample_key = list(phen_dict.keys())[0]\n",
        "        pheno_vect = phen_dict[sample_key]\n",
        "\n",
        "    sim_function = functools.partial(cal_similarity, lim=lim4sim)\n",
        "    crossval_res_kol = []\n",
        "    y_arr = np.array([get_label(f) for f in flist])\n",
        "    flist = np.array(flist)\n",
        "\n",
        "    # Optionally adjust folds based on phenotypic data (as in percenter code)\n",
        "    if len(phen_dict) > 0:\n",
        "        unique_labels, counts = np.unique(y_arr, return_counts=True)\n",
        "        new_n_splits = min(p_fold, counts.min())\n",
        "        if new_n_splits < 2:\n",
        "            print(\"Skipping due to insufficient samples per class when using phenotypic data.\")\n",
        "            # You could exit or set new_n_splits = 2 if that makes sense.\n",
        "        else:\n",
        "            print(f\"Using {new_n_splits}-fold cross-validation with phenotypic data for whole dataset.\")\n",
        "    else:\n",
        "        new_n_splits = p_fold\n",
        "\n",
        "    for rp in range(10):\n",
        "        kf = StratifiedKFold(n_splits=new_n_splits, random_state=1, shuffle=True)\n",
        "        np.random.shuffle(flist)\n",
        "        y_arr = np.array([get_label(f) for f in flist])\n",
        "        for kk, (train_index, test_index) in enumerate(kf.split(flist, y_arr)):\n",
        "            train_samples, test_samples = flist[train_index], flist[test_index]\n",
        "            verbose = (True if (kk == 0) else False)\n",
        "            regions_inds = get_regs(train_samples, int(num_corr / 4))\n",
        "            num_inpp = len(regions_inds)\n",
        "            n_lat = int(num_inpp / 2)\n",
        "\n",
        "            # Include phenotype_data in both train and test loaders.\n",
        "            train_loader = get_loader(data=all_corr, samples_list=train_samples,\n",
        "                                      batch_size=batch_size, mode='train',\n",
        "                                      augmentation=augmentation, aug_factor=aug_factor,\n",
        "                                      num_neighbs=num_neighbs, eig_data=eig_data,\n",
        "                                      similarity_fn=sim_function, verbose=verbose,\n",
        "                                      regions=regions_inds, phenotype_data=phen_dict)\n",
        "\n",
        "            test_loader = get_loader(data=all_corr, samples_list=test_samples,\n",
        "                                     batch_size=batch_size, mode='test',\n",
        "                                     augmentation=False, verbose=verbose,\n",
        "                                     regions=regions_inds, phenotype_data=phen_dict)\n",
        "\n",
        "            model = MTAutoEncoder(tied=True, num_inputs=num_inpp,\n",
        "                                  num_latent=n_lat, use_dropout=use_dropout)\n",
        "            model.to(device)\n",
        "            criterion_ae = nn.MSELoss(reduction='sum')\n",
        "            criterion_clf = nn.BCEWithLogitsLoss()\n",
        "            optimizer = optim.SGD([{'params': model.fc_encoder.parameters(), 'lr': learning_rate_ae},\n",
        "                                   {'params': model.classifier.parameters(), 'lr': learning_rate_clf}],\n",
        "                                  momentum=0.9)\n",
        "\n",
        "            for epoch in range(1, num_epochs + 1):\n",
        "                if epoch <= 20:\n",
        "                    train_losses = train(model, epoch, train_loader, p_bernoulli, mode='both')\n",
        "                else:\n",
        "                    train_losses = train(model, epoch, train_loader, p_bernoulli, mode='clf')\n",
        "\n",
        "            res_mlp = test(model, criterion_ae, test_loader, eval_classifier=True)\n",
        "            crossval_res_kol.append(res_mlp)\n",
        "        print(\"Averages over folds:\")\n",
        "        print(np.mean(np.array(crossval_res_kol), axis=0))\n",
        "        finish = time.time()\n",
        "        print(\"Elapsed time:\", finish - start)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_ROI = \"cc200\"\n",
        "p_fold = 5  # Use 5-fold for intra-site evaluation\n",
        "p_center = \"KKI\"\n",
        "p_mode = \"percenter\"  # Change to \"percenter\" for intra-site evaluation\n",
        "p_augmentation = True\n",
        "p_Method = \"ASD-DiagNet\""
      ],
      "metadata": {
        "id": "lHRl9EzZWivb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if p_Method == \"ASD-DiagNet\" and p_mode == \"percenter\":\n",
        "    num_corr = len(all_corr[flist[0]][0])\n",
        "\n",
        "    if len(phen_dict) > 0:\n",
        "        sample_key = list(phen_dict.keys())[0]\n",
        "        pheno_vect = phen_dict[sample_key]\n",
        "\n",
        "    flist = os.listdir(data_main_path)\n",
        "\n",
        "    for f in range(len(flist)):\n",
        "        flist[f] = get_key(flist[f])\n",
        "\n",
        "    centers_dict = {}\n",
        "    for f in flist:\n",
        "        key = f.split('_')[0]\n",
        "\n",
        "        if key not in centers_dict:\n",
        "            centers_dict[key] = []\n",
        "        centers_dict[key].append(f)\n",
        "\n",
        "    flist = np.array(centers_dict[p_center])\n",
        "    y_arr = np.array([get_label(f) for f in flist])\n",
        "\n",
        "    # Determine the number of splits.\n",
        "    if len(phen_dict) > 0:\n",
        "        unique_labels, counts = np.unique(y_arr, return_counts=True)\n",
        "        new_n_splits = min(p_fold, counts.min())\n",
        "        if new_n_splits < 2:\n",
        "            print(f\"Skipping center {p_center} due to insufficient samples in one class.\")\n",
        "            # Optionally, exit or continue to the next center.\n",
        "        else:\n",
        "            print(f\"Using {new_n_splits}-fold cross-validation for center {p_center}.\")\n",
        "    else:\n",
        "        new_n_splits = p_fold\n",
        "        print(f\"Using {new_n_splits}-fold cross-validation for center {p_center}.\")\n",
        "\n",
        "    flist = np.array(centers_dict[p_center])\n",
        "\n",
        "    start =time.time()\n",
        "    #flist = np.array(sorted(os.listdir(data_main_path)))\n",
        "    batch_size = 8\n",
        "    learning_rate_ae, learning_rate_clf = 0.0001, 0.0001\n",
        "\n",
        "    num_epochs = 25\n",
        "    p_bernoulli = None\n",
        "    augmentation = p_augmentation\n",
        "    use_dropout = False\n",
        "\n",
        "    aug_factor = 2\n",
        "    num_neighbs = 5\n",
        "    lim4sim = 2\n",
        "    n_lat = int(num_corr / 4)\n",
        "\n",
        "    print('p_bernoulli: ', p_bernoulli)\n",
        "    print('augmentation: ', augmentation, 'aug_factor: ', aug_factor,\n",
        "          'num_neighbs: ', num_neighbs, 'lim4sim: ', lim4sim)\n",
        "    print('use_dropout: ', use_dropout, '\\n')\n",
        "\n",
        "    sim_function = functools.partial(cal_similarity, lim=lim4sim)\n",
        "    all_rp_res = []\n",
        "    y_arr = np.array([get_label(f) for f in flist])\n",
        "\n",
        "    # Only continue if we have enough splits.\n",
        "    if len(phen_dict) > 0 and new_n_splits < 2:\n",
        "        pass\n",
        "    else:\n",
        "        for rp in range(10):#loop\n",
        "            print(\"========================\")\n",
        "            crossval_res_kol = []\n",
        "            start_rp = time.time()\n",
        "            kf = StratifiedKFold(n_splits=new_n_splits)\n",
        "            for kk, (train_index, test_index) in enumerate(kf.split(flist, y_arr)):\n",
        "\n",
        "                train_samples, test_samples = flist[train_index], flist[test_index]\n",
        "\n",
        "                verbose = (True if (kk == 0) else False)\n",
        "\n",
        "                regions_inds = get_regs(train_samples, int(num_corr/4))\n",
        "                num_inpp = len(regions_inds)\n",
        "                n_lat = int(num_inpp/2)\n",
        "                num_inpp = len(regions_inds)\n",
        "                if len(phen_dict) > 0:\n",
        "                    train_loader = get_loader(data=all_corr, samples_list=train_samples,\n",
        "                                              batch_size=batch_size, mode='train',\n",
        "                                              augmentation=augmentation, aug_factor=aug_factor,\n",
        "                                              num_neighbs=num_neighbs, eig_data=eig_data, similarity_fn=sim_function,\n",
        "                                              verbose=verbose, regions=regions_inds, phenotype_data=phen_dict)\n",
        "\n",
        "                    test_loader = get_loader(data=all_corr, samples_list=test_samples,\n",
        "                                             batch_size=batch_size, mode='test', augmentation=False,\n",
        "                                             verbose=verbose, regions=regions_inds, phenotype_data=phen_dict)\n",
        "                else:\n",
        "                    train_loader = get_loader(data=all_corr, samples_list=train_samples,\n",
        "                                              batch_size=batch_size, mode='train',\n",
        "                                              augmentation=augmentation, aug_factor=aug_factor,\n",
        "                                              num_neighbs=num_neighbs, eig_data=eig_data, similarity_fn=sim_function,\n",
        "                                              verbose=verbose, regions=regions_inds)\n",
        "\n",
        "                    test_loader = get_loader(data=all_corr, samples_list=test_samples,\n",
        "                                             batch_size=batch_size, mode='test', augmentation=False,\n",
        "                                             verbose=verbose, regions=regions_inds)\n",
        "\n",
        "                model = MTAutoEncoder(tied=True, num_inputs=num_inpp, num_latent=n_lat, use_dropout=use_dropout)\n",
        "                model.to(device)\n",
        "                criterion_ae = nn.MSELoss(reduction='sum')\n",
        "                criterion_clf = nn.BCEWithLogitsLoss()\n",
        "                optimizer = optim.SGD([{'params': model.fc_encoder.parameters(), 'lr': learning_rate_ae},\n",
        "                                       {'params': model.classifier.parameters(), 'lr': learning_rate_clf}],\n",
        "                                      momentum=0.9)\n",
        "\n",
        "                for epoch in range(1, num_epochs + 1):\n",
        "                    if epoch <= 20:\n",
        "                        train_losses = train(model, epoch, train_loader, p_bernoulli, mode='both')\n",
        "                    else:\n",
        "                        train_losses = train(model, epoch, train_loader, p_bernoulli, mode='clf')\n",
        "\n",
        "                res_mlp = test(model, criterion_ae, test_loader, eval_classifier=True)\n",
        "                #print(\"fold\",kk+1,\":\",test(model, criterion_ae, test_loader, eval_classifier=True))\n",
        "                crossval_res_kol.append(res_mlp)\n",
        "            print(\"Result of repeat \",rp,\":\")\n",
        "            print(np.mean(np.array(crossval_res_kol), axis=0))\n",
        "            all_rp_res.append(np.mean(np.array(crossval_res_kol), axis=0))\n",
        "            finish_rp = time.time()\n",
        "\n",
        "            print(\"Running time:\", finish_rp - start_rp)\n",
        "        print(\"Avergae result of 10 repeats: \", np.mean(np.array(all_rp_res), axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1SmoKq_Q51w",
        "outputId": "91b931c5-4f48-45f0-d04a-a4201afbeffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 5-fold cross-validation for center KKI.\n",
            "p_bernoulli:  None\n",
            "augmentation:  True aug_factor:  2 num_neighbs:  5 lim4sim:  2\n",
            "use_dropout:  False \n",
            "\n",
            "========================\n",
            "Result of repeat  0 :\n",
            "[0.69285714 0.         1.        ]\n",
            "Running time: 28.5419442653656\n",
            "========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQd04MATi_mI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}